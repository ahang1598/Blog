

# 1.自我介绍

我是来自暨南大学 - 网络空间安全专业一名研究生，目前研二。

研究方向是城市数据挖掘，目前已经发表了一篇CCF-C类国际会议一篇，获2021校级优秀研究生三等奖。

现在希望参加招聘尽早出去实习，如果可以的话四月份就可以出去实习。

本科GPA3.0 / 4， 研究生GPA3.24 / 4



# 2. 项目

## 2.1 介绍该项目

首先呢，选择这个开源的电商项目主要由于电商的技术点比较多而且新，电商的市场份额也很大。这个前后端分离的项目可以学习到SpringBoot的应用，微服务架构，分布式架构以及相关的项目管理。

这个项目大概实现功能是：

当用户访问时，进行权限校验，验证通过后访问商城信息，可以检索、选择所需商品并下单购买。也提供秒杀抢购业务。

当后台管理员访问通过权限校验后，可以上传更改商品信息。

学完这个项目后，对于项目业务开发的基本流程有了一个了解，对于SpringBoot框架应用，各个微服务在Eureka集群注册后通过Feign调用服务的方便快捷有一定了解。 以及采用RabbitMQ延迟队列机制及设计Redis对商品信息、商品库存量、用户信息高效存储，实现多线程异步秒杀，解决重复排队，超卖等问题。



https://ahang1598.github.io/Blog/#/%E5%A4%8D%E7%9B%98%E9%9D%A2%E7%BB%8F

## 2.2 项目痛点



### 2.2.1出现过哪些问题？

下订单时

```java
发送了一个post请求
http://localhost:18090/order

提交测试数据
{
	"receiverContact" : "szitheima",
	"receiverMobile" : "12345",
	"receiverAddress" : "hahaha"
} 
```

返回了500错误，同时也返回了错误的信息：

表示无法读取`http://goods/sku/decr/count?username=szitheima`

```java

{
    "timestamp": "2022-03-22T08:57:16.689+0000",
    "status": 500,
    "error": "Internal Server Error",
    "message": "Read timed out executing POST http://goods/sku/decr/count?username=szitheima",
    "path": "/order"
}
```

订单的  `OrderController`调用了`orderService.add(order);`，其中`orderServiceImpl`实现中调用了`skuFeign.decrCount(order.getUsername());`

考虑是否为商品微服务没有启动导致微服务无法调用，发现已经启动了，那么就查看商品微服务

查看商品微服务时：`decrCount()`方法会去调用redis缓存数据，那么此时我就去查看redis的缓存是否存在用户的购物车数据，发现没有。

问题最终定位到：对于购物车数据设置了缓存过期时间，导致数据到期后消失，我测试时直接读取下单，没有调用购物车数据，导致了问题。

临时解决：重新添加用户的购物车数据。

永久解决：规范流程，用户先通过购物车页面点选后将购物车数据加载到redis缓存中，然后下单开始减少库存。





### 2.2.2 出现问题后如何解决？

**BUG定位**

1. 对于web服务先明确是浏览器端问题还是服务端问题，通过状态返回码基本定位，检查输入的URL是否与后端提供的API一致。
2. 对于500服务端问题，查看IDEA的异常日志信息，是否有错误报出
3. 有异常时，考虑是内部逻辑问题还是输入数据问题？基本检查下逻辑是否正确，有没有临界值问题，配置问题问题？然后通过调试DEBUG打断点。对于出现问题前的代码打断点，不断调试查看数据是否传递计算正常。
4. 也有其他原因：是否和服务器软件版本及设置有关？













## 2.3 秒杀



**如何控制秒杀商品页面购买按钮的点亮**

控制该按钮是灰色还是点亮，但是为了减轻服务器端负载压力，更好地利用CDN、反向代理等性能优化手段，该页面被设计为静态页面，缓存在CDN、反向代理服务器上，甚至用户浏览器上。秒杀开始时，用户刷新页面，请求根本不会到达应用服务器。

采用Spring的定时任务定时将符合参与秒杀的商品查询出来再存入到Redis缓存，所以这里需要使用到定时任务。**在定时任务类的指定方法上加上@Scheduled开启定时任务**



redis应用一：下单实现

用户下单，为了提升下单速度，我们将订单数据存入到Redis缓存中，如果用户支付了，则将Reids缓存中的订单存入到MySQL中，并清空Redis缓存中的订单。



多线程下单

下订单这里，我们一般采用多线程下单，但多线程中我们又需要保证用户抢单的公平性，也就是先抢先下单。我们可以这样实现，用户进入秒杀抢单，如果用户复合抢单资格，只需要记录用户抢单数据，存入队列，多线程从队列中进行消费即可，存入队列采用左压，多线程下单采用右取的方式。

先开启异步操作，用`@EnableAsync`注解开启，然后在对应的异步方法上添加注解`@Async`即可。

**排队信息封装**

用户每次下单的时候，我们可以创建一个队列进行排队，然后采用多线程的方式创建订单，排队我们可以采用Redis的队列实现。 排队信息中需要有用户抢单的商品信息，主要包含商品ID，商品抢购时间段，用户登录名。

**下单更新抢单状态**

用户每次点击抢购的时候，如果排队成功，则将用户抢购状态存储到Redis中，多线程抢单的时候，如果抢单成功，则更新抢单状态。



防止重复下单排队

用户每次抢单的时候，一旦排队，我们设置一个自增值，让该值的初始值为1，每次进入抢单的时候，对它进行递增，如果值>1，则表明已经排队,不允许重复排队,如果重复排队，则对外抛出异常，并抛出异常信息100表示已经正在排队



**减库存的操作**

有两种选择，一种是**拍下减库存** 另外一种是**付款减库存**；目前采用的**“拍下减库存”**的方式，拍下就是一瞬间的事，对用户体验会好些。



**并发超卖问题解决**

原因：只剩下一个库存时，多线程同时读取都有库存，导致都下单成功

解决：

1）可以利用Redis队列实现，给每件商品创建一个独立的商品个数队列，每次给用户下单的时候，先从队列中取数据，如果能取到数据，则表明有库存，如果取不到，则表明没有库存，这样就可以防止超卖问题产生了。

2）利用悲观锁，对商品库存加锁，这样会导致效率低，多个线程等待一个锁

3）利用乐观锁，这个数据所有请求都有资格去修改，但会获得一个该数据的版本号，只有版本号符合的才能更新成功，其他的返回抢购失败。**它会增大CPU的计算开销**







https://www.jianshu.com/p/df4fbecb1a4b



# 3.优点







漏桶算法

https://www.cnblogs.com/xuwc/p/9123078.html



# Java基础

## Integer与int

int是基本类型，Integer是引用类型，可以将基本类型int包装成一个类

包装类是为了值类型数据和对象间能互相转换、提供装箱和拆箱机制的类



**自动拆箱与装箱**

- 自动拆箱： 自动进行**包装类**向**基本数据类型**的转换
- 自动装箱： 自动进行**基本数据类型**向**包装类**的转换



## == 与 equals

http://t.csdn.cn/Xqfj2

`==`

**基本数据类型** int 比较的是 **值**

**包装类** Integer 比较的是 **地址**



`equals`

`equals`方法**没有重写**还是比较**对象地址**

 **重写**`equals`方法后要看是如何重写的(`Object(地址)、Integer(值)、String(先地址后值、地址不同值相同返回true)`)



## 双亲委派

![](img\basic\classload.png)



# SpringBoot

## 启动过程

![](img\basic\bootStart.png)







# ElasticSearch

## 1. 与关系型数据库对比

应用系统一般需要借助数据产品实现数据查询加速的需求。业界主流的数据产品分为类，一类是传统的关系型数据库，另一类是非关系型数据库。ES属于非关系型数据库。

1. 索引方式

关系型数据库的索引大多是B-Tree结构，而ES使用的是倒排索引，两种不同的数据索引方式决定了这两种产品在某些场景中性能和速度的差异。例如，对一个包含几亿条数据的关系型数据表执行最简单的count查询时，关系型数据库可能需要秒级的响应时间，如果数据表的设计不合理，甚至有可能把整个关系型数据库拖垮，影响其他的数据服务

而ES可以在毫秒级别进行返回，该查询对整个集群的影响微乎其微。再例如，一个需求是进行分词匹配，关系型数据库需要依靠其他的组件才能完成这种查询，查询的结果只能是满足匹配，但是不能按照匹配程度进行打分排序ES建立在Lucene基础之上，与生俱来就能完成分词匹配，并且支持多种打分排序算法，还支持用户自定义排序脚本。

2. 事务支持

事务是关系型数据库的核心组成模块，而**ES是不支持事务**的。ES更新文档时，先读取文档再进行修改，然后再为文档重新建立索引。如果同一个文档同时有多个并发请求，则极有可能会丢失某个更新操作。为了解决这个问题，**ES使用了乐观锁**，即假定冲突是不会发生的，不阻塞当前数据的更新操作，每次更新会增加当前文档的版本号，最新的数据由文档的最新版本来决定，这种机制就决定了ES没有事务管理。因此，如果你的需求是类似商品库存的精准查询或者金融系统的核心并发业务的支持，那么关系型数据是不错的选择。

3. SQL和DSL

SQL和DSL都有自己的语法结构，都是各自和用户之间进行交互的一种语言表达方式。SQL是关系型数据库使用的语言，主要是因为SQL查询的逻辑比较简单和直接，一般是大小、相等之类的比较运算，以及逻辑与、或、非的关系运算。ES不仅包含上述运算，而且支持文本搜索、地理位置搜索等复杂数据的搜索，因此ES使用DSL查询进行请求通信。虽然ES的高版本也开始支持SQL查询，但若需要完成比较复杂的数据搜索需求，使用DSL查询会更加方便快捷。

4. 扩展方式

假设随着业务的增长，我们的数据也迅速膨胀了几倍甚至几十倍。这时需要考虑数据产品扩展方式的难易程度。关系型数据库的扩展，需要借助第三方组件完成分库分表的支持。分库分表即按照某个ID取模将数据打散后分散到不同的数据节点中，借此来分摊集群的压力。但是分库分表有多种策略，需要使用人员对业务数据特别精通才能进行正确的选择。另外，分库分表会对一些业务造成延迟，如查询结果的合并及多表Join操作。

**ES本身就是支持分片的**，只要初期对分片的个数进行了合理的设置，后期是不需要对扩展过分担心的，即使现有集群负载较高，也可以通过后期增加节点和副分片的方式来解决。

5. 数据的查询速度

在少量字段和记录的情况下，传统的关系型数据库的查询速度非常快。如果单表有上百个字段和几十亿条记录，则查询速度是比较慢的。虽然可以通过索引进行缓解，但是随着数据量的增长，查询速度还是会越来越慢。ES是基于Lucene库的搜索引擎，可以支持全字段建立索引。在ES中，单个索引存储上百个字段或几十亿条记录都是没有问题的，并且查询速度也不会变慢。

6. 数据的实时性

关系型数据库存储和查询数据基本上是实时的，即单条数据写入之后可以立即查询。为了提高数据写入的性能，ES在内存和磁盘之间增加了一层系统缓存。ES响应写入数据的请求后，会先将数据存储在内存中，此时该数据还不能被搜索到。内存中的数据**每隔一段时间（默认为1s）被刷新到系统缓存内**，此时数据才能被搜索到。因此，ES的**数据写入不是实时**的，而是准实时的。



## 2.Elasticsearch的架构原理

### 节点职责

节点按照职责可以分为**master节点**、**数据节点**和**协调节点**，每个节点类型可以进行单独配置。默认情况下，集群不会对节点角色进行划分，所有节点都是平等的，可以担任所有的职责。但是在生产环境中需要对这些节点的角色进行最优划分，否则在高并发请求的情况下，集群容易出现服务阻塞超时甚至服务崩溃的隐患。

**master 节点负责维护整个集群的相关工作，管理集群的变更，如创建/删除索引、节点健康状态监测、节点上/下线等**。master节点是由集群节点通过选举算法选举出来的，一个集群中只有一个节点可以成为 master 节点，但是可以有一个或多个节点参与 master 节点的选举。在默认情况下，任意节点都可以作为 master 的候选节点，可以通过配置项node.master对当前节点是否作为master的候选节点进行控制。

**数据节点主要负责索引数据的保存工作，此外也执行数据的其他操作，如文档的删除、修改和查询操作**。数据节点的很多工作是调用Lucene库进行Lucene索引操作，因此这种节点对于内存和I/O的消耗比较大，生产环境中应多注意数据节点的计算机负载情况。

**当然为了降低集群的负载，可以设置某些节点作为单独的协调节点**。在节文件中设置ｎｏｄｅ，ｍｏｓｔｅｒ和ｎｏｄｅ ｄａａ配置项为ｆｏｌｓｅ，此时，这个节点就不会被选中为节点井且不再担任数据节点，而客户端就可以把这类节点作为协调节点来使用，把所有的请求都分发到这些节点上



### 主分片和副分片

前面说过，ES 为了支持分布式搜索，会把数据按照分片进行切分。**一个索引由一个或者多个分片构成，并且每个分片有0个甚至多个副分片。多个分片分布在不同的节点中**，通过这种分布式结构提升了分片数据的高可用性和服务的高并发支持。

那么ES是如何提升分片数据的高可用性的呢

集群中的索引主分片和副分片在不同的计算机上，如果某个主分片所在的节点宕机，则原有的某个副分片会提升为主分片继续对外进行服务。

例如，在如图1.3所示的集群中，如果nodel发生故障宕机，集群感知到分片0的主分片P0将要丢失，此时集群会立即将其他节点（如node3）上的分片0对应的副分片RO 作为主分片P0进行服务。集群中由node2和node3对外提供服务，所有的分片相关的服务不受影响

如果nodel恢复了服务并加入集群中，因为在nodel上还保留有分片0的数据，此时nodel 上的分片 P0 会变成副分片 R0，在此期间缺失的数据会通过 node3上的主分片 PO 进行补充。并且nodel上的分片R1和R2也会分别从node3和node2上对应的P1和P2 分片上补充数据



### 文档读写过程

下面分别介绍ES集群响应客户端的写入和读取请求的过程。

当ES**协调节点接收**到来自客户端对某个索引的**写入文档请求**时，该节点会根据一定的**路由算法将该文档映射到某个主分片上**，然后将请求转发到该分片所在的节点。完成数据的存储后，该节点会将请求**转发给该分片的其他副分片**所在的节点，直到所有副分片节点全部完成写入，ES协调节点向客户端报告写入成功。

如图1.8所示为一个包含3个节点的ES集群，假设索引中只有3个主分片和6个副分片，客户端向节点1发起向索引写入一条文档的请求，在本次请求中，节点1被称为协调节点。节点1判断数据应该映射到哪个分片上。假设将数据映射到分片1上，因为分片1的主分片在节点2上，因此节点1把请求转发到节点2上。节点2接收客户端的数据并进行存储，然后把请求转发到副分片1所在的节点1和节点3上，当所有副分片所在的节点全部完成存储后，协调节点也就是节点1向客户端返回成功标志。



当ES**协调节点接收**到来自客户端的**获取某个索引**的某文档的请求时，协调节点会找到该文档所在的所有分片，然后根据**轮询算法在主/副分片中选择一个分片并将请求转发给该分片所在的节点**，**该节点会将目标数据发送给协调节点，协调节点再将数据返回给客户端。**

如图1.9所示为一个包含3个节点的ES集群，假设索引中只有3个主分片和6个副分片，客户端向节点1发起向索引获取文档的请求，在本次请求中，节点1被称为协调节点。节点1判断数据应该映射到哪个分片上。假设将数据映射到分片1上，分片1有主/副两种分片，分别在节点2、节点1和节点3上。假设此时协调节点的轮询算法选择的是节点3，那么它会将请求转发到节点3上，然后节点3会把数据传输给协调节点，也就是节点1，最后由节点1向客户端返回文档数据。



### 文本的搜索过程

在ES中，一般使用match查询对文本字段进行搜索。match查询过程一般分为如下几步

（1）ES 将查询的字符串传入对应的分析器中，分析器的主要作用是对查询文本进行分词，并把分词后的每个词语变换为对应的底层lucene term 查询。

（2）ES用term查询在倒排索引中查找每个term，然后获取一组包含该term的文档集合。

（3）ES根据文本相关度对每个文档进行打分计算，打分完毕后，ES把文档按照相关

性进行倒序排序。

（4）ES根据得分高低返回匹配的文档。

 



## 3. 正向索引和倒排索引

Lucene和ElasticSearch
lucene:全文搜索工具包，依赖于java，不适用于集群环境
ES：全文搜索服务器，基于lucene，采用Rest HTTP调用方式，对集群支持较好



**正向索引**：逐个扫描文档，匹配出关键词

**当用户在主页上搜索关键词“小米手机”时，假设只存在正向索引（forward index），那么就需要扫描索引库中的所有文档，找出所有包含关键词“小米手机”的文档，再根据打分模型进行打分，排出名次后呈现给用户。**因为互联网上收录在搜索引擎中的文档的数目是个天文数字，**这样的索引结构根本无法满足实时返回排名结果的要求。**



![](img\Interview\855959-20170706154309815-1724421988.png)



**倒排索引**：主要是**根据关键字建立索引**，然后根据关键字找到关键字对应的**排好序的字典**，通过有序字典就可以很快（ O(log n) ）找到对应的**文件列表**

![](img\Interview\inverted-index.png)

![](img\Interview\index.png)

​    **所以，搜索引擎会将正向索引重新构建为倒排索引**，即把文件ID对应到关键词的映射转换为**关键词到文件ID的映射**，每个关键词都对应着一系列的文件，这些文件中都出现这个关键词。![](img\Interview\855959-20170706154505378-610589524.png)



**倒排索引的底层**实现是基于：FST（Finite State Transducer）数据结构。

演示工具：[http://examples.mikemccandless.com/fst.py?terms=&cmd=Build+it%21](http://examples.mikemccandless.com/fst.py?terms=&cmd=Build+it!)

lucene 从 4+版本后开始大量使用的数据结构是 FST。FST 有两个优点：

（1）空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；

（2）查询速度快。O(len(str))的查询时间复杂度。



**Posting List压缩**Frame Of Reference

第一步：对递增的数组，求出两两差值

第二步：分块存储

第三步：找出每一块最大需要的比特数，比如第一块最大227需要8比特，那么三个就需要3*8bits

![](img\Interview\frameOfReference.png)

**联合查询**

如果多个field索引的联合查询，倒排索引如何满足快速查询的要求呢？

- 利用跳表(Skip list)的数据结构快速做“与”运算，或者
- 利用上面提到的bitset按位“与”







# 并发

## 线程池

什么是线程池？

线程池是一种多线程处理形式，处理过程中将任务提交到线程池，任务的执行交由线程池来管理。

如果每个请求都创建一个线程去处理，那么服务器的资源很快就会被耗尽，使用线程池可以减少创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。

 

为什么要使用线程池？

创建线程和销毁线程的花销是比较大的，这些时间有可能比处理业务的时间还要长。这样频繁的创建线程和销毁线程，再加上业务工作线程，消耗系统资源的时间，可能导致系统资源不足。（我们可以把创建和销毁的线程的过程去掉）

 

线程池有什么作用？

线程池作用就是限制系统中执行线程的数量。

1、提高效率 创建好一定数量的线程放在池中，等需要使用的时候就从池中拿一个，这要比需要的时候创建一个线程对象要快的多。

2、方便管理 可以编写线程池管理代码对池中的线程同一进行管理，比如说启动时有该程序创建100个线程，每当有请求的时候，就分配一个线程去工作，如果刚好并发有101个请求，那多出的这一个请求可以排队等候，避免因无休止的创建线程导致系统崩溃。

 

说说几种常见的线程池及使用场景

1、newSingleThreadExecutor

创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

2、newFixedThreadPool

创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。

3、newCachedThreadPool

创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。

4、newScheduledThreadPool

创建一个定长线程池，支持定时及周期性任务执行。

 

线程池中的几种重要的参数

corePoolSize就是线程池中的核心线程数量，这几个核心线程，只是在没有用的时候，也不会被回收

maximumPoolSize就是线程池中可以容纳的最大线程的数量

keepAliveTime，就是线程池中除了核心线程之外的其他的最长可以保留的时间，因为在线程池中，除了核心线程即使在无任务的情况下也不能被清除，其余的都是有存活时间的，意思就是非核心线程可以保留的最长的空闲时间，

util，就是计算这个时间的一个单位。

workQueue，就是等待队列，任务可以储存在任务队列中等待被执行，执行的是FIFIO原则（先进先出）。

threadFactory，就是创建线程的线程工厂。

handler,是一种拒绝策略，我们可以在任务满了之后，拒绝执行某些任务。

 

说说线程池的拒绝策略

    当请求任务不断的过来，而系统此时又处理不过来的时候，我们需要采取的策略是拒绝服务。RejectedExecutionHandler接口提供了拒绝任务处理的自定义方法的机会。在ThreadPoolExecutor中已经包含四种处理策略。

AbortPolicy策略：该策略会直接抛出异常，阻止系统正常工作。

CallerRunsPolicy 策略：只要线程池未关闭，该策略直接在调用者线程中，运行当前的被丢弃的任务。

DiscardOleddestPolicy策略： 该策略将丢弃最老的一个请求，也就是即将被执行的任务，并尝试再次提交当前任务。

DiscardPolicy策略：该策略默默的丢弃无法处理的任务，不予任何处理。

    除了JDK默认提供的四种拒绝策略，我们可以根据自己的业务需求去自定义拒绝策略，自定义的方式很简单，直接实现RejectedExecutionHandler接口即可。

 











execute和submit的区别？

    在前面的讲解中，我们执行任务是用的execute方法，除了execute方法，还有一个submit方法也可以执行我们提交的任务。

这两个方法有什么区别呢？分别适用于在什么场景下呢？我们来做一个简单的分析。

execute适用于不需要关注返回值的场景，只需要将线程丢到线程池中去执行就可以了。

submit方法适用于需要关注返回值的场景

 

五种线程池的使用场景

newSingleThreadExecutor：一个单线程的线程池，可以用于需要保证顺序执行的场景，并且只有一个线程在执行。

newFixedThreadPool：一个固定大小的线程池，可以用于已知并发压力的情况下，对线程数做限制。

newCachedThreadPool：一个可以无限扩大的线程池，比较适合处理执行时间比较小的任务。

newScheduledThreadPool：可以延时启动，定时启动的线程池，适用于需要多个后台线程执行周期任务的场景。

newWorkStealingPool：一个拥有多个任务队列的线程池，可以减少连接数，创建当前可用cpu数量的线程来并行执行。

 

线程池的关闭

关闭线程池可以调用shutdownNow和shutdown两个方法来实现

shutdownNow：对正在执行的任务全部发出interrupt()，停止执行，对还未开始执行的任务全部取消，并且返回还没开始的任务列表。

shutdown：当我们调用shutdown后，线程池将不再接受新的任务，但也不会去强制终止已经提交或者正在执行中的任务。

 

初始化线程池时线程数的选择

如果任务是IO密集型，一般线程数需要设置2倍CPU数以上，以此来尽量利用CPU资源。

如果任务是CPU密集型，一般线程数量只需要设置CPU数加1即可，更多的线程数也只能增加上下文切换，不能增加CPU利用率。

上述只是一个基本思想，如果真的需要精确的控制，还是需要上线以后观察线程池中线程数量跟队列的情况来定。

 

线程池都有哪几种工作队列

1、ArrayBlockingQueue

是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序。

2、LinkedBlockingQueue

一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列

3、SynchronousQueue

一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。

4、PriorityBlockingQueue

一个具有优先级的无限阻塞队列。
————————————————
版权声明：本文为CSDN博主「Linias」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_29373285/article/details/85238728



**线程池大小**

如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 NCPU+1

如果是IO密集型任务，参考值可以设置为2*NCPU

![](img\Interview\threadNums.png)







# 数据库

## B+树时间复杂度

 https://zhuanlan.zhihu.com/p/402951795

一个含有`n`个值，阶为`m`的B+树: $log_mn$

通过这个可以定位到子节点，对子节点读取时是一次IO全部读取，不需要考虑子节点遍历问题了。

广泛用于文件系统及数据库中

- Windows：HPFS文件系统
- Mac：HFS，HFS+文件系统
- Linux：ResiserFS，XFS，Ext3FS，JFS文件系统
- 数据库：ORACLE，MYSQL，SQLSERVER等中

B+树详解http://t.csdn.cn/idBcv

![](img\Interview\20200420151803292.png)

## B+树三层能存多少数据

https://www.cnblogs.com/leefreeman/p/8315844.html

在MySQL中InnoDB页的大小默认是16k

单个叶子节点（页）中的记录数=16K/1K=16。（这里假设一行记录的数据大小为1k）

非叶子节点能存放多少指针
		我们假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，这样一共14字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即16384/14=1170。那么可以算出一棵高度为2的B+树，能存放1170*16=18720条这样的数据记录。

高度为3的B+树可以存放：1170*1170*16=21902400条这样的记录



## 乐观锁和悲观锁各自适用场景

https://www.cnblogs.com/qiuhaitang/p/12485395.html

悲观锁和乐观锁是数据库**用来保证数据并发安全，防止更新丢失**的两种方法，两者大部分场景下差异不大，一些独特场景下有一些差别，一般我们可以从以下几方面来分析：

1. **响应速度**：如果需要非常高的响应速度，建议采用**乐观锁**方案，成功就执行，不成功就失败，不需要等待其他并发去释放锁；
2. **冲突频率**：如果冲突频率非常高，建议采用悲观锁，保证成功率，如果冲突频率大，乐观锁会需要重试多次才能成功，代价比较大；
3. **重试代价**：如果重试代价大，建议采用悲观锁；

**悲观锁**适合**写**操作非常多的场景

**乐观锁**适合**读**操作非常多的场景，因为不加锁的话，性能会有大幅度的提升。

`阿里java规范手册`提及：

`并发修改同一记录`时，避免更新丢失，需要加锁。要么在应用层加锁，要么在`缓存加锁`，要么在`数据库层使用乐观锁`，使用 version 作为更新依据。
说明：如果每次访问`冲突概率小于 20%`，推荐使用`乐观锁`，否则使用悲观锁。乐观锁的重试次数不得小于3 次。

【推荐】资金相关的`金融敏感信息`，`使用悲观锁`策略。
说明：乐观锁在获得锁的同时已经完成了更新操作，校验逻辑容易出现漏洞，另外，乐观锁对冲突的解决策略有较复杂的要求，处理不当容易造成系统压力或数据异常，所以资金相关的金融敏感信息不建议使用乐观锁更新。

## MySQL数据库如何解决高并发

https://juejin.cn/post/6869265425696292871

基本上，我们优化要从几个关键字入手：**短距离**，**少数据**，**分散压力**。

### **短距离**

> 所谓的短距离，指的是从前端到数据库的路径要短。

1. **页面静态**。有些页面的数据是在某些时段是不变的，那么这个页面可以静态化，这样可以提高访问的速度。
2. **使用缓存**。缓存大家都知道，快的原因就是基于内存。所以使用基于内存的缓存的话，可以减少对数据库的访问，同时加速访问速度。
3. **批量读取**。高并发的情况下，可以将多个请求的查询合在一次进行，以减少对数据库的访问速度。
4. **延迟修改**。延迟修改的意思高并发的情况下可能是将多次修改数据放在缓存中，然后定时将缓存中的数据过更新到数据库；也可以是通过缓存的同步策略通过解析异步同步到数据库中。
5. **使用索引**。这个不用说了，索引有着比较多的类型，例如普通索引/主键索引/组合索引/全文索引等。

### **少数据**

> 所谓的少数据，其实是查询的数据要少。

1. **分表**。所谓的分表，其实有水平切分和垂直拆分。玩过单机的小伙伴都知道，往往一些具有历史性的表单，都会有成百上千万级别的数据。这样子对于 MySQL 来说，即使是加了索引，SQL 方面继续优化，也很难做到更快的查询速度。那么我们可以通过分表的操作来实现。例如说最常见的我们可以根据时间的维度来进行表的水平拆分，今年的数据保持下来，而去年的数据可以存在另外一个表里。
2. **分离活跃数据**。其实这个有点类似缓存，但是不同之处在于数据还是在 MySQL 上面的。例如一个查询商品的业务，有一些火爆/经常被搜索的商品可以存在一张活跃表。查询的时候先查询活跃表，没有的话再查询总商品表。
3. **分块**。这个分块有点类似于算法里面的“索引顺序查找”。通过数据层面的优化，将数据放在不同的块中，而我们只需要计算找到对应的块就行了。

### **分散压力**

> 所谓的分散压力，其实是分散不同数据库服务器的压力

1. **集群**。集群的概念相信大家都很清楚，对于业务服务器来说其实就是具备相同业务流程的服务器部署多台，通过负载均衡或其他方式来将请求分配到不同服务器。而数据库也一样，通过特定的规则策略将数据导向特定的数据库服务器上。
2. **分布式**。所谓的分布式，其实就是将原本处于同个流程的业务逻辑分配到不同的服务器上面执行，达到了“并发”执行的效果，加快执行速度。
3. **分库分表**。分库分表主要是水平拆分和垂直拆分。对于访问频率高而数据量巨大的单表，可以减少单表的数据，根据特定的维度进行水平拆分，增加数据库的吞吐量，这就是**分表水平拆分**；而对于业务耦合性低的多表来说，可以将不同的表存储在不同的数据库上，对数据库进行垂直拆分，提高数据库写的能力，即**分库的垂直拆分**。
4. **建立主从**。建立主从的目的其实就是为了读写分离。我们都知道，只要数据库的事务级别够高，那么并发读是不会影响到数据的混乱，而并发写则会。所以建立主从一般来说，写会留在主服务器上写，而会在从服务器上读。**所以基本上让主服务器进行事务性操作，从服务器进行 select 查询。这样子的话，事务性操作（增加/删除/修改）导致的改变更新同步到集群中的从数据库**。



## Redis命令执行过程

第一步是建立连接阶段，响应了socket的建立，并且创建了client对象；第二步是处理阶段，从socket读取数据到输入缓冲区，然后解析并获得命令，执行命令并将返回值存储到输出缓冲区中；第三步是数据返回阶段，将返回值从输出缓冲区写到socket中，返回给客户端，最后关闭client。

![](img\redis\1816118-20191211184555471-1138003842.jpg)

![](img\redis\1816118-20191211185055009-1899949689.png)



# Java基础

## NIO VS BIO

[参考](https://mp.weixin.qq.com/s/B4ndlwKrUcXlQ0n0JkH3wg)

BIO全称是Blocking IO，同步阻塞式IO

服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理

服务器具备了高并发能力，即能够同时处理多个客户端请求了，但是却带来了一个问题，随着开启的线程数目增多，将会消耗过多的内存资源，导致服务器变慢甚至崩溃



NIO全称是Non-blocking，同步非阻塞IO

服务器实现模式为一个线程处理多个请求(连接)，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求就进行处理



![](img\Java\niobio.png)

Channel 是 NIO 的核心概念，它表示一个打开的连接，这个连接可以连接到 I/O 设备（例如：磁盘文件，Socket）或者一个支持 I/O 访问的应用程序，Java NIO 使用缓冲区和通道来进行数据传输。

![](img\Java\niobio1.png)

## hashcode使用场景

一般用于`HashMap, HashSet`中判断key是否相同

`HashMap`中put源码中会去判断

```java
if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k))))
```

也就是先调用hashcode方法判断是否相同

如果hashcode相同，再去判断equals方法，如果也相同就表明为同一个key



重写方式

```java
public class Student {
    private int age;
    private String name;
    private int score;
	

	@Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;
        Student student = (Student) o;
        return age == student.age &&
                score == student.score &&
                Objects.equals(name, student.name);
    }

    @Override
    public int hashCode() {
        return Objects.hash(age, name, score);
    }
}
```



# 设计模式

参考[1](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485303&idx=1&sn=9e4626a1e3f001f9b0d84a6fa0cff04a&chksm=cea248bcf9d5c1aaf48b67cc52bac74eb29d6037848d6cf213b0e5466f2d1fda970db700ba41&token=255050878&lang=zh_CN%23rd), [2](https://www.runoob.com/design-pattern/design-pattern-tutorial.html)

## 软件设计原则

开闭原则：对拓展开放，修改关闭

里氏代换原则：子类继承父类时，不要去重写父类已有的方法

依赖倒转原则：依赖于接口而不要依赖于具体实现

接口隔离原则：实现一个类时不用实现多余的接口

迪米特法则：不直接与对方通信，通过中间代理转发，降低依赖

合成复用原则：尽量用聚合组合代替继承实现



## 单例设计模式

**介绍**：对于某些对象只需要创建一次，且只能有一个，那么就可以用单例设计模式。对于频繁使用的对象，可以省略创建对象所花费的时间。

**应用实例：**一些设备管理器常常设计为单例模式，比如一个电脑有两台打印机，在输出的时候就要处理不能两台打印机打印同一个文件

**Spring 中 bean 的默认作用域就是 singleton(单例)的。** 除了 singleton 作用域，Spring 中 bean 还有下面几种作用域：

- prototype : 每次请求都会创建一个新的 bean 实例。
- request : 每一次HTTP请求都会产生一个新的bean，该bean仅在当前HTTP request内有效。
- session : 每一次HTTP请求都会产生一个新的 bean，该bean仅在当前 HTTP session 内有效。





> 单例设计模式分类两种：
>
> ​	饿汉式：类加载就会导致该单实例对象被创建	
>
> ​	懒汉式：类加载不会导致该单实例对象被创建，而是首次使用该对象时才会创建

饿汉式

```java
/**
 * 饿汉式
 *      静态变量创建类的对象
 */
public class Singleton {
    //私有构造方法
    private Singleton() {}

    //在成员位置创建该类的对象
    private static Singleton instance = new Singleton();

    //对外提供静态方法获取该对象
    public static Singleton getInstance() {
        return instance;
    }
}
```



懒汉式

```java
/**
 * 双重检查方式
 */
public class Singleton {

    //私有构造方法
    private Singleton() {}
	
    // 添加volatile
    private static volatile Singleton instance;

   //对外提供静态方法获取该对象
    public static Singleton getInstance() {
		//第一次判断，如果instance不为null，不进入抢锁阶段，直接返回实际
        if(instance == null) {
            synchronized (Singleton.class) {
                //抢到锁之后再次判断是否为空
                if(instance == null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

- 序列化、反序列方式破坏单例模式的解决方法

​		在Singleton类中添加`readResolve()`方法，在反序列化时被反射调用，如果定义了这个方法，就返回这个方法的值，如果没有定义，则返回新new出来的对象。

- 反射方式破解单例的解决方法
  ```java
  添加代码
  if(instance != null) {
      throw new RuntimeException();
  }
  ```

## 原型模式

**定义：**用于创建当前对象的克隆

**应用**：JAVA 中的 Object clone() 方法





## 工厂模式

**定义：**一个用于创建对象的接口，让子类决定将哪一个类实例化

**优点**： 1、一个调用者想创建一个对象，只要知道其名称就可以了。 2、扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以。 3、屏蔽产品的具体实现，调用者只关心产品的接口。

**缺点**：每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事。



Spring使用工厂模式可以通过 `BeanFactory` 或 `ApplicationContext` 创建 bean 对象。

**两者对比：**

- `BeanFactory` ：延迟注入(使用到某个 bean 的时候才会注入),相比于`BeanFactory`来说会占用更少的内存，程序启动速度更快。
- `ApplicationContext` ：容器启动的时候，不管你用没用到，一次性创建所有 bean 。

`ApplicationContext`的三个实现类：

1. `ClassPathXmlApplication`：把上下文文件当成类路径资源。
2. `FileSystemXmlApplication`：从文件系统中的 XML 文件载入上下文定义信息。
3. `XmlWebApplicationContext`：从Web系统中的XML文件载入上下文定义信息。



## 代理模式

**定义**：为其他对象提供一种代理以控制对这个对象的访问

**应用**：火车票代售点

**优点**： 1、职责清晰。 2、高扩展性。 3、智能化。

**缺点**： 1、由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。 2、实现代理模式需要额外的工作，有些代理模式的实现非常复杂。

**注意事项**：
		 1、**和适配器模式的区别**：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口。 		 2、**和装饰器模式的区别**：装饰器模式为了增强功能，而代理模式是为了加以控制。



**Spring AOP 就是基于动态代理的**，如果要代理的对象，实现了某个接口，那么Spring AOP会使用**JDK Proxy**，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候Spring AOP会使用**Cglib** ，这时候Spring AOP会使用 **Cglib** 生成一个被代理对象的子类来作为代理





## 适配器模式

**定义：**将一个类的接口转换成调用者希望的另外一个接口。[适配器模式]()是的原本由于接口不兼容而不能在一起工作的那些类可以一起工作。

**应用：** 读卡器是作为内存卡和笔记本之间的适配器

**优点**： 1、可以让任何两个没有关联的类一起运行。 2、提高了类的复用。 3、增加了类的透明度。 4、灵活性好。

**缺点**： 1、过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是 A 接口，其实内部被适配成了 B 接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。 2.由于 JAVA 至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类。



**spring MVC中的适配器模式**

在Spring MVC中，`DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`。解析到对应的 `Handler`（也就是我们平常说的 `Controller` 控制器）后，开始由`HandlerAdapter` 适配器处理。`HandlerAdapter` 作为期望接口，具体的适配器实现类用于对目标类进行适配，`Controller` 作为需要适配的类。

**为什么要在 Spring MVC 中使用适配器模式？** Spring MVC 中的 `Controller` 种类众多，不同类型的 `Controller` 通过不同的方法来对请求进行处理。



## 观察者模式

**定义**：当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知它的依赖对象。

**应用**：公众号订阅

**优点：**

* 降低了目标与观察者之间的耦合关系，两者之间是抽象耦合关系。
* 被观察者发送通知，所有注册的观察者都会收到信息【可以实现广播机制】

**缺点：**

* 如果观察者非常多的话，那么所有的观察者收到被观察者发送的通知会耗时
* 如果被观察者有循环依赖的话，那么被观察者发送通知会使观察者循环调用，会导致系统崩溃

`Spring`的事件驱动模型具体实现如下：

1. 定义一个事件: 实现一个继承自 `ApplicationEvent`，并且写相应的构造函数；
2. 定义一个事件监听者：实现 `ApplicationListener` 接口，重写 `onApplicationEvent()` 方法；
3. 使用事件发布者发布消息: 可以通过 `ApplicationEventPublisher` 的 `publishEvent()` 方法发布消息。





# 分布式

## hash一致性

参考[1](https://www.jianshu.com/p/528ce5cd7e8f)

对于多台服务设备，为了平均分配hash空间（0 ~ $2^{32}$-1），通过对设备个数取模，将整个Hash空间组织成一个虚拟的圆环。每台设备包含圆环的一部分。

**可拓展性**

当添加新设备时，将其插入圆环的一处后，只需要移动一部分数据到新服务器即可，不需要所有服务器改变。

**容错性**

当某一台设备挂掉后，为了防止数据倾斜导致部分服务器压力大，所以虚拟了多个节点，均匀的将虚拟节点映射到实际节点既可以保证均匀分配地址。

**哈希偏斜**
在实际的映射中，服务器映射到哈希环上很有可以是斜的，称为哈希偏斜，在hash环偏斜的情况下，**大部分的缓存对象很有可能会缓存到一台服务器上**。导致缓存分布极度不均匀，三台服务器没有被平均的使用，如果缓存数据较多的服务器失效，由于失效的缓存太多，在这种情况下，很有可能引起系统的故障，
解决方式：
要想均衡的将缓存分布到服务器上，要让服务器尽量的多，这样才能均匀的出现在哈希环上，解决方式是：**增加虚拟节点**
真实的服务器资源只要三台，但 可以根据现有的物理节点映射许多新的节点，比如：a->a1,a2……an,再**将虚拟节点加入哈希环**
**引入虚拟节点后，虚拟节点越多，哈希环上的服务器节点就越多，缓存被均匀分布的概率就越大**，这样就可以一定程度上减小哈希环偏斜带来的影响，在进行缓存读写时，可以先找到缓存对应的虚拟节点，再找到对应的真实节点，再进行缓存数据的存储和读取。



## Hash冲突解决

开放定址法: 所谓的开放定址法就是一旦发生了冲突,就去寻找下一个空的散列地址,只要散列表足够大,空的散列地址总能找到

再哈希法: 再哈希法又叫双哈希法,有多个不同的Hash函数,当发生冲突时,使用第二个,...

链地址法: 链地址法的基本思想是:每个哈希表节点都有一个next指针



## 幂等性

[参考](https://zhuanlan.zhihu.com/p/269115765)

幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。

### 为什么要幂等性？

前端重复提交选中的数据，后台只产生对应这个数据的一个反应结果。

**token机制**
当客户端请求页面时，服务器会生成一个随机数token，并且将token放置到session当中，然后将token发给客户端（一般通过构造hidden表单）。下次客户端提交请求时，token会随着表单一起提交到服务器端。服务器端第一次验证相同过后，会将session中的token值更新下，若用户重复提交，第二次的验证判断将失败，因为用户提交的表单中的token没变，但服务器端session中token已经改变了。

**乐观锁**--**通过版本号实现**

update table_xxx set name=#name#,version=version+1 where version=#version#；通过条件限制 update table_xxx set avai_amount=avai_amount-#subAmount# where avai_amount-#subAmount# >= 0要求：quality-#subQuality# >= ，这个情景适合不用版本号，只更新是做数据安全校验，适合库存模型，扣份额和回滚份额，性能更高；

**redis的setnx怎么做幂等性的?** 

redis实现幂等很简单，我以redis实现接口的幂等性为例说明。你可以自定义一个幂等注解，然后配合AOP进行方法拦截，对拦截的请求信息(包括方法名+参数名+参数值)根据固定的规则去生成一个key，然后调用redis的setnx方法，如果返回ok，则正常调用方法，否则就是重复调用了。这样可以保证重复请求接口在一定时间内只会被成功处理一次。至于锁的有效时长要根据业务情况而定的。



**一、出现非幂等性的情况**

1、生产者已把消息发送到mq，在mq给生产者返回ack的时候网络中断，故生产者未收到确定信息，生产者认为消息未发送成功，但实际情况是，mq已成功接收到了消息，在网络重连后，生产者会重新发送刚才的消息，造成mq接收了重复的消息

2、消费者在消费mq中的消息时，mq已把消息发送给消费者，消费者在给mq返回ack时网络中断，故mq未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息；

**二、解决办法**

1、mq接收生产者传来的消息：

mq内部会为每条消息生成一个全局唯一、与业务无关的消息id，当mq接收到消息时，会**先根据该id判断消息是否重复发送**，mq再决定是否接收该消息。

2、消费者消费mq中的消息：

也可利用mq的该id来判断，或者可按自己的规则生成一个全局唯一id，每次消费消息时**用该id先判断该消息是否已消费过**



# Nginx

**1、Nginx负载均衡的原理是什么？**
 客户端向反向代理发送请求，接着反向代理根据某种负载机制转发请求至目标服务器(这些服务器都运行着相同的应用)，并把获得的内容返回给客户端，期中，代理请求可能根据配置被发往不同的服务器。

**2、Nginx负载均衡的作用是什么？**
 负载均衡：分摊到多个操作单元上进行执行，和它的英文名称很匹配。就是我们需要一个调度者，保证所有后端服务器都将性能充分发挥，从而保持服务器集群的整体性能最优，这就是负载均衡。

**3、Nginx负载均衡算法有哪些？**
**源地址哈希法**：根据获取客户端的IP地址，通过哈希函数计算得到一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。
**轮询法**：将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。
**随机法**：通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。
**加权轮询法**：不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。
**加权随机法**：与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。
**最小连接数法**：由于后端服务器的配置不尽相同，对于请求的处理有快有慢，最小连接数法根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器。







# 注册中心

## Eureka

### 原理

Eurka 工作流程

1、Eureka Server 启动成功，等待服务端注册。在启动过程中如果配置了集群，集群之间定时通过 Replicate 同步注册表，每个 Eureka Server 都存在独立完整的服务注册表信息

2、Eureka Client 启动时根据配置的 Eureka Server 地址去注册中心注册服务

3、Eureka Client 会每 30s 向 Eureka Server 发送一次心跳请求，证明客户端服务正常

4、当 Eureka Server 90s 内没有收到 Eureka Client 的心跳，注册中心则认为该节点失效，会注销该实例

5、单位时间内 Eureka Server 统计到有大量的 Eureka Client 没有上送心跳，则认为可能为网络异常，进入自我保护机制，不再剔除没有上送心跳的客户端

6、当 Eureka Client 心跳请求恢复正常之后，Eureka Server 自动退出自我保护模式

7、**Eureka Client 定时全量或者增量从注册中心获取服务注册表**，并且将获取到的信息缓存到本地

8、**服务调用时，Eureka Client 会先从本地缓存找寻调取的服务。如果获取不到，先从注册中心刷新注册表，再同步到本地缓存**

9、Eureka Client 获取到目标服务器信息，发起服务调用

10、Eureka Client 程序关闭时向 Eureka Server 发送取消请求，Eureka Server 将实例从注册表中删除



### AP

Eureka Server 的同步遵循着一个非常简单的原则：只要有一条边将节点连接，就可以进行信息传播与同步。所以，如果存在多个节点，只需要将节点之间两两连接起来形成通路，那么其它注册中心都可以共享信息。每个 Eureka Server 同时也是 Eureka Client，多个 Eureka Server 之间通过 P2P 的方式完成服务注册表的同步。

Eureka Server 集群之间的状态是采用**异步方式同步**的，所以不保证节点间的状态一定是一致的，不过基本能保证最终状态是一致的。


## Zookeeper原理

RPC服务注册、发现过程简述如下：

1.服务提供者启动时，会将其服务名称，ip地址注册到配置中心。

2.服务消费者在第一次调用服务时，会通过注册中心找到相应的服务的IP地址列表，并缓存到本地，以供后续使用。当消费者调用服务时，不会再去请求注册中心，而是直接通过负载均衡算法从IP列表中取一个服务提供者的服务器调用服务。

3.当服务提供者的某台服务器宕机或下线时，相应的ip会从服务提供者IP列表中移除。同时，注册中心会将新的服务IP地址列表发送给服务消费者机器，缓存在消费者本机。

4.当某个服务的所有服务器都下线了，那么这个服务也就下线了。

5.同样，当服务提供者的某台服务器上线时，注册中心会将新的服务IP地址列表发送给服务消费者机器，缓存在消费者本机。

6.服务提供方可以根据服务消费者的数量来作为服务下线的依据。



### zookeeper和eureka的区别在哪?

eureka遵守AP原则,zookeeper遵守CP原则

Zookeeper

当向注册中心查询服务列表时,我们可以容忍注册中心返回的是几分钟以前的注册信息,但不能接受服务直接down掉不可用。也就是说,服务注册功能对可用性的要求要高于一致性。

但是zk会出现这样一种情况,当master节点因为网络故障与其他节点失去取系时,剩余节点会重新进行leader选举。问题在于,选举leader的时间太长, 30 ~ 120s,且选举期间整个2k集群都是不可用的,这就导致在选举期间注册服务瘫痪。在云部署的环境下,因网络问题使得zk集群失去master节点是较大概率会发生的事,虽然服务能够恢复,但是漫长的选举时间导致的注册长期不可用是不能容忍的.

 

Eureka

Eureka着明白了这一点,因此在设计时就优先保证可用性。

Eureka各个节点都是平等的,几个节点挂掉不会影响正常节点的工作剩余的节点依然可以提供注册和查询服务。

而Eureka的客户端在向某个Eureka注册或时如果发现连接失败,则会自动切换至其它节点,只要有一台Eureka还在,就能保证注册服务可用(保证可用性),只不过查到的信息可能不是最新的(不保证强一致性)。

除此之外, Eureka还有一种自我保护机制,如果在15分钟内超过85%的节点都没有正常的心跳,那么Eureka就认为客户端与注册中心出现了网络故障,此时会出现以下几种情况

1, Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务

2.Eureka仍然能够接受新服务的注册和查询请求,但是不会被同步到其它节点上(即保证当前节点依然可用)

3,当网络稳定时,当前实例新的注册信息会被同步到其它节点中.

因此, Eureka可以很好的应对因网络故障导致部分节点失去联系的情况,而不会像zookeeper那样便整个注册服务瘫痪。



## Nacos

https://developer.aliyun.com/article/698930





# JVM

## 内存溢出

**内存溢出（Out Of Memory）** ：申请内存时，JVM没有足够的内存空间。堆、直接内存、元空间都会导致，而虚拟机栈和方法栈会导致StackOverflowError栈溢出。



## 内存泄漏

[参考](http://www.gxitsky.com/article/1603347575608495)

> **内存泄露 （Memory Leak）**：申请了内存，但是没有释放，导致内存空间浪费。
>   长生命周期对象持有短生命周期对象的引用，尽管短生命周期对象不再使用，但是因为长生命周期对象持有它的引用（短生命周期对象到 GC Roots 是通路的）而导致不能被回收。



### 原因

1. **静态集合类**：如 HashMap，Vector，静态容器的生命周期与应用程序一致。如果容器内的对象不再使用，则存在内存泄漏。

​			**预防：**尽量不使用静态变量。

2. **各种连接，流**：如 数据库连接，网络连接，IO连接，流等。例如，创建的连接不再使用时，需要调用 **close** 方法关闭连接，只有连接被关闭后，GC 才会回收对应的对象（Connection，Statement，ResultSet，Session）。忘记关闭这些资源会导致持续占有内存，无法被 GC 回收。

​			**预防：**使用 `finally`块关闭资源。

3. **监听器**：应用可能会用到多个监听器，但在释放目标对象的同时往往没有删除相应的监听器。

4. **变量不合理的作用域**：一个变量的定义作用域大于其使用范围，很可能存在内存泄漏；或不再使用对象没有及时将对象设置为 null，很可能导致内存泄漏的发生。
   **例如**，只在方法内使用的对象，定义为了成员变量，方法内使用完后因被外部对象导致不能及时地被回收，就存在内存泄漏。

5. **引用了外部类的非静态内部类**：非静态内部类（或匿名类）的初始化总是需要依赖外部类的实例。默认情况下，每个非静态内部类都包含对其**包含类**的隐式引用，若在程序中使用这个内部类对象，那么**即使在包含类对象超出范围之后，也不会被回收**（内部类对象隐式地持有外部类对象的引用，使其成不能被回收）。

​			**预防：**如果内部类不需要访问对其包含类的成员，应将其转换为静态类。

6. **单例模式**：单例对象在初始化后会以静态变量的方式在 JVM 的整个生命周期中存在。如果单例对象持有外部的引用，那么这个外部对象将不能被 GC 回收，导致内存泄漏。

​			**预防：**尽可能使用懒加载，而不是立即加载。

6. **改变对象哈希值**：当对象存储在一个 Hash 容器中（HashSet，HashMap），就不能修改这个对象中那些参与计算哈希值的字段。
   否则，对象修改后的哈希值与之前存储进容器的哈希值就不同，在此情况下，即使在`contains`方法使用该对象的当前引用作为的参数去容器中检索对象也是找不到的，这会导致无法从容器中**单独删除**当前对象，造成内存泄露。

7. **子类重写finalize()**：每当重写类的 `finalize()`方法，该类的对象不会立即被垃圾收集。相反，GC 将它们排队等待最终确定，回收将在稍后的时间点发生。如果用 `finalize()`方法编写的代码不是最佳的，并且**终结器队列**无法跟上Java垃圾收集器，那么迟早将产生 `OutOfMemoryError`。

​			**预防：**应该总是避免重写 `finalize`。

8. **ThreadLocal** 造成的内存泄漏：ThreadLocal 可以实现变量的线程隔离，但若使用不当，就可能会引入内存泄漏问题。
   一旦线程结束不再存在，ThreadLocals 应该被垃圾回收。但是当 ThreadLocals 与 Tomcat 一起使用则可能出现问题。
   Tomcat 使用线程池中的线程来处理请求，而不是每个请求都创建新的线程。线程复用情况下，线程中的 ThreadLocals 并不会被回收，即 ThreadLocal 仍被线程对象持有。ThreadLocal 的生命周期不等于 Request 的生命周期，而是与线程生命周期绑定。
   **预防：**在不使用 ThreadLocals 中的变量时调用 remove() 方法删除当前线程的变量值。
   不能使用 `ThreadLocal.set(null)` 来清除该值。此操作实际是查找当前线程的 `ThreadLocalMap`，键是当前线程对象，将值设置 `null`（这段内容需要看源码比较好量解）。
   最好将 `ThreadLocal` 视为 `finally` 块中关闭的资源，以确保它始终会被关闭。



### 排查

处理内存泄漏没有一个通用的或标准的解决方案，但可以根据应用的一些症状表现来分析定位内存泄漏，使用一些方法以最大限度地减少内存泄漏。

**内存泄漏可能的症状表现：**

- 应用程序长时间连续运行时性能严重下降
- CPU 使用率飙升，甚至到 100%
- 频繁 Full GC，各种报警，例如接口超时报警等
- 应用程序抛出 `OutOfMemoryError` 错误
- 应用程序偶尔会耗尽连接对象
